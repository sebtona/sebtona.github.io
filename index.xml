<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on Aharon Sebton</title>
    <link>https://sebtona.github.io/</link>
    <description>Recent content in Home on Aharon Sebton</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Â© Aharon Sebton 2023</copyright>
    <lastBuildDate>Wed, 05 Jul 2023 17:00:00 -0500</lastBuildDate><atom:link href="https://sebtona.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Bin Packing Robotic System</title>
      <link>https://sebtona.github.io/portfolio/bin-packing-robotic-system/</link>
      <pubDate>Wed, 05 Jul 2023 17:00:00 -0500</pubDate>
      
      <guid>https://sebtona.github.io/portfolio/bin-packing-robotic-system/</guid>
      <description>My graduate research aims at creating an accessible robotic system that can be used to test various 3D bin packing algorithms. An arm robot was integrated with a depth sensing camera so that given a random set of objects, each object can be grasped, 3D scanned, and packed into a container in a pose based on chosen criteria.
A neural network (GR-ConvNet) created by RIT alumn and fellow roboticist Sulabh Kumra was repurposed to allow the Sawyer arm robot to grasp random objects that are in the robot&amp;rsquo;s workspace and in the field of view of an overhead Intel RealSense Depth Camera D435.</description>
    </item>
    
    <item>
      <title>Gesture Controlled Drone Simulation</title>
      <link>https://sebtona.github.io/portfolio/gesture-controlled-drone-simulation/</link>
      <pubDate>Mon, 08 May 2023 17:00:00 -0500</pubDate>
      
      <guid>https://sebtona.github.io/portfolio/gesture-controlled-drone-simulation/</guid>
      <description>I worked in a team with two of my fellow students on a final project for our Biorobotics/Cybernetics class. The goals of the project were to create a machine learning model capable of accurately classifying a predetermined set of hand and arm gestures based on a user&amp;rsquo;s biosignals, and to use said model to control a quadcopter drone&amp;rsquo;s trajectory in a real time simulation environment.
We began this project by agreeing on a set of fifteen hand/arm gestures that map to commands for the drone to move and rotate along all axes in 3D space.</description>
    </item>
    
    <item>
      <title>Coming soon</title>
      <link>https://sebtona.github.io/post/coming-soon/</link>
      <pubDate>Sat, 14 May 2022 18:00:00 -0500</pubDate>
      
      <guid>https://sebtona.github.io/post/coming-soon/</guid>
      <description>&lt;p&gt;New blog posts coming soon&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Sawyer Mobile Device Interaction</title>
      <link>https://sebtona.github.io/portfolio/sawyer-mobile-device-interaction/</link>
      <pubDate>Wed, 27 Apr 2022 17:00:00 -0500</pubDate>
      
      <guid>https://sebtona.github.io/portfolio/sawyer-mobile-device-interaction/</guid>
      <description>For my final project in my Advanced Robotics class, I proposed a method of enabling the collaborative arm robot Sawyer (by Rethink Robotics) to perform single and multi-touch gestures on a mobile device. The purpose of this project is twofold. One is to allow for automated smartphone and mobile application testing through cobots. The other purpose is to eventually allow for cobot teleoperation through human biological signals, such as EMG or gaze, so that people with mobility-limiting disabilities may fully control touch screen devices without use of their arms.</description>
    </item>
    
    <item>
      <title>Mathematical Image Reconstruction</title>
      <link>https://sebtona.github.io/portfolio/mathematical-image-reconstruction/</link>
      <pubDate>Thu, 04 Nov 2021 12:30:00 -0500</pubDate>
      
      <guid>https://sebtona.github.io/portfolio/mathematical-image-reconstruction/</guid>
      <description>This MATLAB project completed in my Advanved Engineering Mathematics course demonstrates how eigenvectors and eigenvalues can be used for image re-synthesis and compression. I learned the following important takeaways by completing this project:
Any image can be represented as a set of eigenpairs (eigenvalues and corresponding eigenvectors). Original Cameraman Image and Plot of Eigenvalues
Some image eigenvalues have greater magnitudes than others. Magnitude of Eigenvalues of Image
When reconstructing an image, eigenvalues with greater magnitudes contribute more information to the image than eigenvalues with smaller magnitudes when paired with their corresponding eigenvectors.</description>
    </item>
    
    <item>
      <title>Dancing Hexapod</title>
      <link>https://sebtona.github.io/portfolio/dancing-hexapod/</link>
      <pubDate>Wed, 27 Oct 2021 18:00:00 -0500</pubDate>
      
      <guid>https://sebtona.github.io/portfolio/dancing-hexapod/</guid>
      <description>The inspiration for my final project in my Principles of Robotics class stemmed from Boston Dynamics&amp;rsquo; video of their dancing robots. I proposed the creation of a hexapod (six-legged) mobile robot that could accurately detect the tempo of a song or audio file being played, and perform a set of dance moves that are synchronized to the beat. As a stretch goal, I wanted the hexapod to move toward the audio source before dancing, just as a human would at a concert.</description>
    </item>
    
    <item>
      <title>Mathematical Edge Detection</title>
      <link>https://sebtona.github.io/portfolio/mathematical-edge-detection/</link>
      <pubDate>Thu, 14 Oct 2021 12:30:00 -0500</pubDate>
      
      <guid>https://sebtona.github.io/portfolio/mathematical-edge-detection/</guid>
      <description>This MATLAB project completed in my Advanved Engineering Mathematics course demonstrates gradient and Laplacian edge detection techniques, and their caveats with grayscale images. I learned the following important takeaways by completing this project:
Taking the gradient of an image in any direction (by convolving the image with a kernel) will result in an intuitive visualization of how quickly pixel values change in said direction. This can be used as a crude edge detection method.</description>
    </item>
    
    <item>
      <title>Pediatric Test Mannequin</title>
      <link>https://sebtona.github.io/portfolio/pediatric-test-mannequin/</link>
      <pubDate>Wed, 26 May 2021 18:00:00 -0500</pubDate>
      
      <guid>https://sebtona.github.io/portfolio/pediatric-test-mannequin/</guid>
      <description>For my Multidisciplinary Senior Design (MSD) project, I worked on a team to develop the sensing system for the &amp;ldquo;pediatric test mannequin&amp;rdquo;: an anthropomorphic test device for a motorized pediatric stander. The motorized pediatric stander kit was developed by a previous MSD team to enable children with limited mobility to manually control their motion. This test mannequin was designed with the purpose of collecting data to characterize the stander&amp;rsquo;s performance and the rider&amp;rsquo;s experience/safety.</description>
    </item>
    
  </channel>
</rss>
